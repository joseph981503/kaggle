{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array, hstack\n",
    "from sklearn import metrics, cross_validation, linear_model\n",
    "from scipy import sparse\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "SEED = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "all_data = np.vstack((train_data.iloc[:,1:-1], test_data.iloc[:,1:-1]))\n",
    "submit = \"sampleSubmission.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = np.shape(train_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_data(data, degree=3, hash=hash):\n",
    "    \"\"\"\n",
    "    numpy.array -> numpy.array\n",
    "\n",
    "    Groups all columns of data into all combinations of triples\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "    m,n = data.shape\n",
    "    for indicies in combinations(range(n), degree):\n",
    "        new_data.append([hash(tuple(v)) for v in data[:,indicies]])\n",
    "    return array(new_data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OneHotEncoder(data, keymap=None):\n",
    "     \"\"\"\n",
    "     OneHotEncoder takes data matrix with categorical columns and\n",
    "     converts it to a sparse binary matrix.\n",
    "\n",
    "     Returns sparse binary matrix and keymap mapping categories to indicies.\n",
    "     If a keymap is supplied on input it will be used instead of creating one\n",
    "     and any categories appearing in the data that are not in the keymap are\n",
    "     ignored\n",
    "     \"\"\"\n",
    "     if keymap is None:\n",
    "          keymap = []\n",
    "          for col in data.T:\n",
    "               uniques = set(list(col))\n",
    "               keymap.append(dict((key, i) for i, key in enumerate(uniques)))\n",
    "     total_pts = data.shape[0]\n",
    "     outdat = []\n",
    "     for i, col in enumerate(data.T):\n",
    "          km = keymap[i]\n",
    "          num_labels = len(km)\n",
    "          spmat = sparse.lil_matrix((total_pts, num_labels))\n",
    "          for j, val in enumerate(col):\n",
    "               if val in km:\n",
    "                    spmat[j, km[val]] = 1\n",
    "          outdat.append(spmat)\n",
    "     outdat = sparse.hstack(outdat).tocsr()\n",
    "     return outdat, keymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_test_submission(filename, prediction):\n",
    "    content = ['id,ACTION']\n",
    "    for i, p in enumerate(prediction):\n",
    "        content.append('%i,%f' %(i+1,p))\n",
    "    f = open(filename, 'w')\n",
    "    f.write('\\n'.join(content))\n",
    "    f.close()\n",
    "#    print 'Saved'\n",
    "\n",
    "# This loop essentially from Paul's starter code\n",
    "def cv_loop(X, y, model, N):\n",
    "    mean_auc = 0.\n",
    "    for i in range(N):\n",
    "        X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "                                       X, y, test_size=.20,\n",
    "                                       random_state = i*SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict_proba(X_cv)[:,1]\n",
    "        auc = metrics.roc_auc_score(y_cv, preds)\n",
    "        print (\"AUC (fold %d/%d): %f\" % (i + 1, N, auc))\n",
    "        if i==100: \n",
    "            break\n",
    "        mean_auc += auc\n",
    "    return mean_auc/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp = group_data(all_data, degree=2)\n",
    "dt = group_data(all_data, degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = array(train_data.ACTION)\n",
    "X = all_data[:num_train]\n",
    "X_2 = dp[:num_train]\n",
    "X_3 = dt[:num_train]\n",
    "\n",
    "X_test = all_data[num_train:]\n",
    "X_test_2 = dp[num_train:]\n",
    "X_test_3 = dt[num_train:]\n",
    "\n",
    "X_train_all = np.hstack((X, X_2, X_3))\n",
    "X_test_all = np.hstack((X_test, X_test_2, X_test_3))\n",
    "num_features = X_train_all.shape[1]\n",
    "model = linear_model.LogisticRegression()\n",
    "Xts = [OneHotEncoder(X_train_all[:,[i]])[0] for i in range(num_features)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_hist = []\n",
    "N = 10\n",
    "good_features = set([])\n",
    "    # Greedy feature selection loop\n",
    "while len(score_hist) < 2 or score_hist[-1][0] > score_hist[-2][0]:\n",
    "    scores = []\n",
    "    for f in range(len(Xts)):\n",
    "        if f not in good_features:\n",
    "            feats = list(good_features) + [f]\n",
    "            Xt = sparse.hstack([Xts[j] for j in feats]).tocsr()\n",
    "#            score = cv_loop(Xt, y, model, N)\n",
    "            scores.append((score, f))\n",
    "#                print (\"Feature: %i Mean AUC: %f\" % (f, score))\n",
    "    good_features.add(sorted(scores)[-1][1])\n",
    "    score_hist.append(sorted(scores)[-1])\n",
    "#        print (\"Current features: %s\" % sorted(list(good_features)))\n",
    "\n",
    "    # Remove last added feature from good_features\n",
    "good_features.remove(score_hist[-1][1])\n",
    "good_features = sorted(list(good_features))\n",
    "#    print (\"Selected features %s\" % good_features))\n",
    "\n",
    "#    print (\"Performing hyperparameter selection...\")\n",
    "    # Hyperparameter selection loop\n",
    "score_hist = []\n",
    "Xt = sparse.hstack([Xts[j] for j in good_features]).tocsr()\n",
    "Cvals = np.logspace(-4, 4, 15, base=2)\n",
    "for C in Cvals:\n",
    "    model.C = C\n",
    "#    score = cv_loop(Xt, y, model, N)\n",
    "    score_hist.append((score,C))\n",
    "#        print (\"C: %f Mean AUC: %f\" %(C, score))\n",
    "bestC = sorted(score_hist)[-1][1]\n",
    "#    print (\"Best C value: %f\" % (bestC))\n",
    "\n",
    "#    print (\"Performing One Hot Encoding on entire dataset...\")\n",
    "Xt = np.vstack((X_train_all[:,good_features], X_test_all[:,good_features]))\n",
    "Xt, keymap = OneHotEncoder(Xt)\n",
    "X_train = Xt[:num_train]\n",
    "X_test = Xt[num_train:]\n",
    "\n",
    "#    print (\"Training full model...\")\n",
    "model.fit(X_train, y)\n",
    "\n",
    "#    print (\"Making prediction and saving results...\")\n",
    "preds = model.predict_proba(X_test)[:,1]\n",
    "create_test_submission(submit, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
